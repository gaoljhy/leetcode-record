# 统计词频

## 题目

```txt
写一个 bash 脚本以统计一个文本文件 words.txt 中每个单词出现的频率。

为了简单起见，你可以假设：

words.txt只包括小写字母和 ' ' 。
每个单词只由小写字母组成。
单词间由一个或多个空格字符分隔。
示例:

假设 words.txt 内容如下：

the day is sunny the the
the sunny is is
你的脚本应当输出（以词频降序排列）：

the 4
is 3
sunny 2
day 1
说明:

不要担心词频相同的单词的排序问题，每个单词出现的频率都是唯一的。
你可以使用一行 Unix pipes 实现吗？
```

### 来源：力扣（LeetCode）
链接：<https://leetcode-cn.com/problems/word-frequency>

著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。


## 解决思路

1. 先用 cat 传递words.txt 内容 `cat words.txt`
2. 使用 tr 留下 words.txt 单词,空格,换行  `tr -cd 'a-z,A-Z,\n, '`
3. 将空格转换为换行 `tr ' ' '\n'`
4. 去除多余空行 `tr -s '\n'`
5. 排序 `sort` (`uniq` 需要先执行`sort`一下)
6. 统计每行出现次数 `uniq -c`
7. 根据词频降序排序 `sort -nr` (`-gr`,`-nr`都对,`nr`快一点)
7. 默认空格分隔,先输出字符串 后输出数字 `awk '{print $2,$1}'`

> 步骤`2`中留下的 换行 是防止换行符前后单词连在一块
> 可以使用 `tr '[:lower:]' '[:upper:]'` 替换大小写

## 答案

`cat words.txt | tr -cd 'a-z,A-Z,\n, ' | tr -s ' ' '\n' | tr -s '\n' | sort | uniq -c | sort -nr |   awk '{print $2,$1}' `